You are adding a <class 'transformers.trainer_callback.DefaultFlowCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is
:DefaultFlowCallback
WandbCallback
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'learning_rate' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'weight_decay' was locked by 'sweep' (ignored update).
  0%|                                                                                                  | 0/7900 [00:00<?, ?it/s]You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.








  2%|█▊                                                                                      | 158/7900 [00:18<14:02,  9.19it/s]
  6%|█████▍                                                                                      | 4/68 [00:01<00:20,  3.13it/s]













 99%|█████████████████████████████████████████████████████████████████████████████████████████▋ | 67/68 [00:25<00:00,  2.49it/s]









  4%|███▍                                                                                    | 310/7900 [02:18<14:17,  8.85it/s]
  4%|███▌                                                                                    | 316/7900 [02:18<14:05,  8.97it/s]












100%|███████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:24<00:00,  3.01it/s]










  6%|█████▎                                                                                  | 474/7900 [04:51<14:03,  8.81it/s]
  3%|██▋                                                                                         | 2/68 [00:00<00:11,  5.75it/s]












 94%|█████████████████████████████████████████████████████████████████████████████████████▋     | 64/68 [00:22<00:01,  2.82it/s]









  8%|██████▉                                                                                 | 628/7900 [07:12<14:52,  8.14it/s]
  8%|███████                                                                                 | 632/7900 [07:13<13:43,  8.83it/s]














 97%|████████████████████████████████████████████████████████████████████████████████████████▎  | 66/68 [00:27<00:00,  2.41it/s]










 10%|████████▊                                                                               | 790/7900 [08:29<13:13,  8.97it/s]
{'loss': 0.0879, 'learning_rate': 0.00013738969664601024, 'epoch': 5.0}




 97%|████████████████████████████████████████████████████████████████████████████████████████▎  | 66/68 [00:26<00:00,  2.44it/s]









 12%|██████████▍                                                                             | 935/7900 [10:41<13:04,  8.87it/s]
 12%|██████████▌                                                                             | 948/7900 [10:43<12:49,  9.03it/s]














 99%|█████████████████████████████████████████████████████████████████████████████████████████▋ | 67/68 [00:26<00:00,  2.43it/s]









 14%|████████████                                                                           | 1101/7900 [11:49<12:38,  8.96it/s]
 14%|████████████▏                                                                          | 1106/7900 [11:50<12:42,  8.91it/s]












 99%|█████████████████████████████████████████████████████████████████████████████████████████▋ | 67/68 [00:25<00:00,  2.52it/s]










 16%|█████████████▊                                                                         | 1259/7900 [13:21<12:34,  8.80it/s]
 16%|█████████████▉                                                                         | 1264/7900 [13:22<12:19,  8.98it/s]













100%|███████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:27<00:00,  2.70it/s]










 18%|███████████████▌                                                                       | 1411/7900 [15:10<13:24,  8.07it/s]
 18%|███████████████▋                                                                       | 1422/7900 [15:11<12:07,  8.90it/s]













 96%|██████████████████████████████████████████████████████████████████████████████████████▉    | 65/68 [00:26<00:01,  2.44it/s]










 20%|█████████████████▎                                                                     | 1571/7900 [16:08<11:48,  8.93it/s]
 20%|█████████████████▍                                                                     | 1580/7900 [16:09<11:36,  9.07it/s]













 97%|████████████████████████████████████████████████████████████████████████████████████████▎  | 66/68 [00:26<00:00,  2.43it/s]










 22%|███████████████████                                                                    | 1729/7900 [17:04<11:49,  8.70it/s]
 22%|███████████████████▏                                                                   | 1738/7900 [17:05<11:39,  8.80it/s]














100%|███████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:27<00:00,  2.73it/s]










 24%|████████████████████▊                                                                  | 1885/7900 [18:40<11:38,  8.61it/s]
 24%|████████████████████▉                                                                  | 1896/7900 [18:41<10:57,  9.13it/s]














 99%|█████████████████████████████████████████████████████████████████████████████████████████▋ | 67/68 [00:26<00:00,  2.46it/s]










 26%|██████████████████████▌                                                                | 2054/7900 [19:54<10:31,  9.25it/s]
{'loss': 0.0698, 'learning_rate': 0.00011297859507719426, 'epoch': 13.0}













 99%|█████████████████████████████████████████████████████████████████████████████████████████▋ | 67/68 [00:25<00:00,  2.61it/s]









 28%|████████████████████████▎                                                              | 2206/7900 [22:04<10:44,  8.83it/s]
 28%|████████████████████████▎                                                              | 2212/7900 [22:05<10:23,  9.13it/s]













100%|███████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:26<00:00,  2.81it/s]











 30%|██████████████████████████                                                             | 2370/7900 [25:35<10:28,  8.79it/s]
{'loss': 0.0639, 'learning_rate': 0.00010687581968499026, 'epoch': 15.0}













 99%|█████████████████████████████████████████████████████████████████████████████████████████▋ | 67/68 [00:25<00:00,  2.79it/s]










 32%|███████████████████████████▊                                                           | 2525/7900 [28:04<10:28,  8.55it/s]
 32%|███████████████████████████▊                                                           | 2528/7900 [28:05<09:59,  8.96it/s]













100%|███████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:26<00:00,  2.79it/s]











 34%|█████████████████████████████▌                                                         | 2686/7900 [29:18<09:45,  8.91it/s]
{'loss': 0.0614, 'learning_rate': 0.00010077304429278627, 'epoch': 17.0}













100%|███████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:27<00:00,  2.79it/s]











 36%|███████████████████████████████▎                                                       | 2844/7900 [30:58<09:16,  9.08it/s]
{'loss': 0.0584, 'learning_rate': 9.772165659668426e-05, 'epoch': 18.0}












100%|███████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:25<00:00,  2.99it/s]










 38%|████████████████████████████████▉                                                      | 2994/7900 [33:43<09:08,  8.95it/s]
 38%|█████████████████████████████████                                                      | 3002/7900 [33:44<09:06,  8.97it/s]













 99%|█████████████████████████████████████████████████████████████████████████████████████████▋ | 67/68 [00:24<00:00,  2.71it/s]









 40%|██████████████████████████████████▊                                                    | 3160/7900 [36:37<08:41,  9.10it/s]
  0%|                                                                                                    | 0/68 [00:00<?, ?it/s]













 97%|████████████████████████████████████████████████████████████████████████████████████████▎  | 66/68 [00:26<00:00,  2.54it/s]











 42%|████████████████████████████████████▌                                                  | 3318/7900 [38:29<08:29,  8.99it/s]
{'loss': 0.0509, 'learning_rate': 8.856749350837828e-05, 'epoch': 21.0}





100%|███████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:26<00:00,  2.69it/s]





 44%|██████████████████████████████████████▎                                                | 3476/7900 [39:53<08:13,  8.96it/s]
{'loss': 0.0502, 'learning_rate': 8.551610581227627e-05, 'epoch': 22.0}







100%|███████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:25<00:00,  2.77it/s]










 46%|███████████████████████████████████████▉                                               | 3628/7900 [40:43<08:07,  8.76it/s]
 46%|████████████████████████████████████████                                               | 3634/7900 [40:43<07:51,  9.06it/s]













 99%|█████████████████████████████████████████████████████████████████████████████████████████▋ | 67/68 [00:26<00:00,  2.43it/s]


 46%|████████████████████████████████████████                                               | 3634/7900 [41:11<07:51,  9.06it/s][34m[1mwandb[39m[22m: Ctrl + C detected. Stopping sweep.
Traceback (most recent call last):
  File "hyperparameter-search.py", line 125, in train
    trainer.train()
  File "/home/ndeo/.conda/envs/capstone-rnn/lib/python3.8/site-packages/transformers/trainer.py", line 1553, in train
    return inner_training_loop(
  File "/home/ndeo/.conda/envs/capstone-rnn/lib/python3.8/site-packages/transformers/trainer.py", line 1942, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/home/ndeo/.conda/envs/capstone-rnn/lib/python3.8/site-packages/transformers/trainer.py", line 2265, in _maybe_log_save_evaluate
    self._save_checkpoint(model, trial, metrics=metrics)
  File "/home/ndeo/.conda/envs/capstone-rnn/lib/python3.8/site-packages/transformers/trainer.py", line 2362, in _save_checkpoint
    torch.save(self.optimizer.state_dict(), os.path.join(output_dir, OPTIMIZER_NAME))
  File "/home/ndeo/.conda/envs/capstone-rnn/lib/python3.8/site-packages/torch/serialization.py", line 380, in save
    return
  File "/home/ndeo/.conda/envs/capstone-rnn/lib/python3.8/site-packages/torch/serialization.py", line 214, in __exit__
    self.file_like.close()
Exception