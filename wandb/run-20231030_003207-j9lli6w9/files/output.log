You are adding a <class 'transformers.trainer_callback.DefaultFlowCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is
:DefaultFlowCallback
WandbCallback
wandb: WARNING Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'learning_rate' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'weight_decay' was locked by 'sweep' (ignored update).
  0%|          | 0/1975 [00:00<?, ?it/s]You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.





  4%|▍         | 79/1975 [00:12<04:19,  7.31it/s]
  3%|▎         | 2/68 [00:00<00:13,  4.89it/s]














 97%|█████████▋| 66/68 [00:26<00:00,  2.45it/s]






  8%|▊         | 156/1975 [02:21<04:34,  6.63it/s]
  8%|▊         | 158/1975 [02:22<04:08,  7.30it/s]











100%|██████████| 68/68 [00:23<00:00,  2.90it/s]







 12%|█▏        | 234/1975 [03:28<04:53,  5.93it/s]
 12%|█▏        | 237/1975 [03:28<04:13,  6.84it/s]








100%|██████████| 68/68 [00:14<00:00,  4.91it/s]






 16%|█▌        | 313/1975 [04:52<04:16,  6.48it/s]
 16%|█▌        | 316/1975 [04:52<03:53,  7.11it/s]









100%|██████████| 68/68 [00:18<00:00,  3.87it/s]







 20%|█▉        | 393/1975 [06:30<03:51,  6.83it/s]
 20%|██        | 395/1975 [06:30<03:39,  7.18it/s]










 99%|█████████▊| 67/68 [00:21<00:00,  3.08it/s]







 24%|██▍       | 471/1975 [07:58<03:45,  6.68it/s]
 24%|██▍       | 474/1975 [07:58<03:30,  7.14it/s]










 94%|█████████▍| 64/68 [00:19<00:01,  3.17it/s]






 28%|██▊       | 549/1975 [09:10<03:45,  6.31it/s]
 28%|██▊       | 553/1975 [09:11<03:35,  6.61it/s]












100%|██████████| 68/68 [00:24<00:00,  2.97it/s]







 32%|███▏      | 632/1975 [10:15<02:58,  7.54it/s]
  3%|▎         | 2/68 [00:00<00:10,  6.25it/s]











 94%|█████████▍| 64/68 [00:20<00:01,  3.11it/s]






 36%|███▌      | 711/1975 [10:57<03:09,  6.67it/s]
  4%|▍         | 3/68 [00:00<00:15,  4.15it/s]











 99%|█████████▊| 67/68 [00:22<00:00,  2.91it/s]







 40%|███▉      | 788/1975 [11:42<03:05,  6.40it/s]
 40%|████      | 790/1975 [11:42<02:49,  7.00it/s]











 93%|█████████▎| 63/68 [00:21<00:01,  2.93it/s]







 44%|████▍     | 869/1975 [12:24<02:41,  6.85it/s]
{'loss': 2.3352, 'learning_rate': 0.0005453310834806954, 'epoch': 11.0}












 94%|█████████▍| 64/68 [00:25<00:01,  2.46it/s]






 48%|████▊     | 945/1975 [13:20<02:34,  6.67it/s]
 48%|████▊     | 948/1975 [13:21<02:25,  7.04it/s]










 97%|█████████▋| 66/68 [00:21<00:00,  3.06it/s]








 52%|█████▏    | 1027/1975 [14:02<02:12,  7.14it/s]
{'loss': 2.4246, 'learning_rate': 0.00046791660801802706, 'epoch': 13.0}














 94%|█████████▍| 64/68 [00:27<00:01,  2.29it/s]






 56%|█████▌    | 1104/1975 [14:54<02:18,  6.29it/s]
 56%|█████▌    | 1106/1975 [14:55<02:02,  7.07it/s]














 93%|█████████▎| 63/68 [00:27<00:02,  2.30it/s]







 60%|█████▉    | 1184/1975 [16:25<01:58,  6.65it/s]
 60%|██████    | 1185/1975 [16:25<01:51,  7.08it/s]














100%|██████████| 68/68 [00:29<00:00,  2.51it/s]


 60%|██████    | 1185/1975 [17:26<11:37,  1.13it/s]
{'train_runtime': 1046.219, 'train_samples_per_second': 120.171, 'train_steps_per_second': 1.888, 'train_loss': 2.513574424775844, 'epoch': 15.0}