You are adding a <class 'transformers.trainer_callback.DefaultFlowCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is
:DefaultFlowCallback
WandbCallback
wandb: WARNING Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'learning_rate' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'weight_decay' was locked by 'sweep' (ignored update).
















  4%|▍         | 315/7875 [00:34<13:08,  9.59it/s]
{'loss': 0.3503, 'learning_rate': 9.618502469820034e-05, 'epoch': 1.0}













 93%|█████████▎| 63/68 [00:25<00:02,  2.45it/s]
















  8%|▊         | 616/7875 [02:34<12:36,  9.60it/s]
  8%|▊         | 630/7875 [02:35<12:32,  9.63it/s]














100%|██████████| 68/68 [00:27<00:00,  2.62it/s]


















 12%|█▏        | 945/7875 [04:10<12:06,  9.53it/s]
{'loss': 0.0951, 'learning_rate': 8.817490367244143e-05, 'epoch': 3.0}













 97%|█████████▋| 66/68 [00:27<00:00,  2.21it/s]


















 16%|█▌        | 1260/7875 [05:31<11:30,  9.58it/s]
{'loss': 0.0857, 'learning_rate': 8.418255763738062e-05, 'epoch': 4.0}












100%|██████████| 68/68 [00:25<00:00,  3.02it/s]


















 20%|█▉        | 1573/7875 [07:06<10:55,  9.61it/s]
 20%|██        | 1575/7875 [07:06<10:52,  9.65it/s]














 99%|█████████▊| 67/68 [00:27<00:00,  2.40it/s]

















 24%|██▍       | 1889/7875 [08:28<10:15,  9.73it/s]
 24%|██▍       | 1890/7875 [08:28<10:14,  9.75it/s]













100%|██████████| 68/68 [00:25<00:00,  2.93it/s]
















 28%|██▊       | 2205/7875 [09:55<09:44,  9.71it/s]
  4%|▍         | 3/68 [00:00<00:16,  3.84it/s]













100%|██████████| 68/68 [00:24<00:00,  3.21it/s]

















 32%|███▏      | 2520/7875 [12:05<09:12,  9.70it/s]
{'loss': 0.0705, 'learning_rate': 6.81623155858628e-05, 'epoch': 8.0}












100%|██████████| 68/68 [00:25<00:00,  2.90it/s]


















 36%|███▌      | 2835/7875 [14:14<08:37,  9.75it/s]
{'loss': 0.0691, 'learning_rate': 6.415725507298334e-05, 'epoch': 9.0}














100%|██████████| 68/68 [00:26<00:00,  2.78it/s]

















 40%|███▉      | 3148/7875 [16:24<08:17,  9.51it/s]
 40%|████      | 3150/7875 [16:24<08:09,  9.65it/s]













100%|██████████| 68/68 [00:27<00:00,  2.73it/s]

















 44%|████▍     | 3465/7875 [18:33<07:35,  9.67it/s]
  0%|          | 0/68 [00:00<?, ?it/s]















100%|██████████| 68/68 [00:27<00:00,  2.74it/s]

















 48%|████▊     | 3778/7875 [20:32<06:59,  9.77it/s]
 48%|████▊     | 3780/7875 [20:33<06:57,  9.80it/s]














100%|██████████| 68/68 [00:26<00:00,  2.76it/s]

















 52%|█████▏    | 4095/7875 [22:21<06:30,  9.69it/s]
  4%|▍         | 3/68 [00:00<00:16,  4.02it/s]














100%|██████████| 68/68 [00:36<00:00,  1.38it/s]

{'eval_loss': 0.07346600294113159, 'eval_bleu': 88.573, 'eval_exact_match': 0.7403, 'eval_spot_acc': 0.7486, 'eval_gen_len': 15.0195, 'eval_runtime': 39.5662, 'eval_samples_per_second': 27.245, 'eval_steps_per_second': 1.719, 'epoch': 13.0}

 52%|█████▏    | 4095/7875 [23:59<22:08,  2.84it/s]