You are adding a <class 'transformers.trainer_callback.DefaultFlowCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is
:DefaultFlowCallback
WandbCallback
wandb: WARNING Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'learning_rate' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'weight_decay' was locked by 'sweep' (ignored update).






























  2%|▏         | 629/31450 [01:01<49:50, 10.31it/s]
  4%|▍         | 3/68 [00:00<00:16,  3.96it/s]












 94%|█████████▍| 64/68 [00:22<00:01,  2.82it/s]






























  4%|▍         | 1258/31450 [02:33<49:03, 10.26it/s]
  0%|          | 0/68 [00:00<?, ?it/s]













 97%|█████████▋| 66/68 [00:25<00:00,  2.58it/s]































  6%|▌         | 1883/31450 [04:12<47:07, 10.46it/s]
  6%|▌         | 1887/31450 [04:12<46:57, 10.49it/s]













 99%|█████████▊| 67/68 [00:27<00:00,  2.43it/s]































  8%|▊         | 2514/31450 [05:48<46:13, 10.43it/s]
  8%|▊         | 2516/31450 [05:48<46:01, 10.48it/s]













 99%|█████████▊| 67/68 [00:27<00:00,  2.41it/s]































 10%|█         | 3145/31450 [07:23<44:49, 10.53it/s]
  4%|▍         | 3/68 [00:00<00:17,  3.71it/s]














 97%|█████████▋| 66/68 [00:26<00:00,  2.43it/s]






























 12%|█▏        | 3774/31450 [09:03<43:57, 10.49it/s]
{'loss': 0.1961, 'learning_rate': 0.0005182742013994608, 'epoch': 6.0}












 99%|█████████▊| 67/68 [00:25<00:00,  2.58it/s]
































 14%|█▍        | 4403/31450 [10:34<43:06, 10.46it/s]
{'loss': 0.1476, 'learning_rate': 0.0005064982207369509, 'epoch': 7.0}













100%|██████████| 68/68 [00:27<00:00,  2.62it/s]































 16%|█▌        | 5032/31450 [12:10<41:50, 10.52it/s]
  4%|▍         | 3/68 [00:00<00:15,  4.13it/s]












100%|██████████| 68/68 [00:24<00:00,  3.07it/s]































 18%|█▊        | 5661/31450 [13:42<40:50, 10.52it/s]
  4%|▍         | 3/68 [00:00<00:17,  3.80it/s]













 96%|█████████▌| 65/68 [00:24<00:01,  2.68it/s]






























 20%|██        | 6290/31450 [15:14<39:51, 10.52it/s]
  3%|▎         | 2/68 [00:00<00:13,  4.92it/s]














 94%|█████████▍| 64/68 [00:25<00:01,  2.42it/s]






























 22%|██▏       | 6919/31450 [16:49<38:59, 10.49it/s]
  0%|          | 0/68 [00:00<?, ?it/s]












 91%|█████████ | 62/68 [00:22<00:02,  2.81it/s]






























 24%|██▍       | 7548/31450 [18:19<37:45, 10.55it/s]
{'loss': 0.1047, 'learning_rate': 0.0004476183174244016, 'epoch': 12.0}












 96%|█████████▌| 65/68 [00:23<00:01,  2.70it/s]






























 26%|██▌       | 8177/31450 [19:52<36:27, 10.64it/s]
  4%|▍         | 3/68 [00:00<00:15,  4.10it/s]













 96%|█████████▌| 65/68 [00:24<00:01,  2.44it/s]






























 28%|██▊       | 8806/31450 [21:28<35:44, 10.56it/s]
  3%|▎         | 2/68 [00:00<00:13,  4.73it/s]













 93%|█████████▎| 63/68 [00:24<00:02,  2.48it/s]






























 30%|███       | 9435/31450 [23:01<34:56, 10.50it/s]
{'loss': 0.0954, 'learning_rate': 0.00041229037543687196, 'epoch': 15.0}













 97%|█████████▋| 66/68 [00:25<00:00,  2.59it/s]






























 32%|███▏      | 10064/31450 [24:42<33:44, 10.57it/s]
  4%|▍         | 3/68 [00:00<00:17,  3.80it/s]












 97%|█████████▋| 66/68 [00:23<00:00,  2.86it/s]






























 34%|███▍      | 10693/31450 [26:13<33:22, 10.36it/s]
  0%|          | 0/68 [00:00<?, ?it/s]










