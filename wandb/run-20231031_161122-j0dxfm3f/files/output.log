You are adding a <class 'transformers.trainer_callback.DefaultFlowCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is
:DefaultFlowCallback
WandbCallback
wandb: WARNING Config item 'gradient_accumulation_steps' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'learning_rate' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'weight_decay' was locked by 'sweep' (ignored update).
  0%|          | 0/15750 [00:00<?, ?it/s]You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
































  2%|▏         | 315/15750 [01:11<54:54,  4.69it/s]
{'loss': 2.2624, 'learning_rate': 2.7924826126771452e-06, 'epoch': 1.0}




















 96%|█████████▌| 65/68 [00:41<00:01,  1.66it/s]



































  4%|▍         | 630/15750 [03:13<53:19,  4.73it/s]
{'loss': 0.2637, 'learning_rate': 5.639188188707245e-06, 'epoch': 2.0}




















100%|██████████| 68/68 [00:41<00:00,  1.68it/s]



































  6%|▌         | 944/15750 [05:18<52:51,  4.67it/s]
  6%|▌         | 945/15750 [05:18<52:19,  4.72it/s]






















 94%|█████████▍| 64/68 [00:42<00:02,  1.48it/s]


































  8%|▊         | 1260/15750 [07:24<50:33,  4.78it/s]
{'loss': 0.1295, 'learning_rate': 1.1332599340767443e-05, 'epoch': 4.0}






















 99%|█████████▊| 67/68 [00:45<00:00,  1.47it/s]



































 10%|█         | 1575/15750 [09:32<49:59,  4.73it/s]
{'loss': 0.2658, 'learning_rate': 1.4179304916797541e-05, 'epoch': 5.0}




















 99%|█████████▊| 67/68 [00:41<00:00,  1.61it/s]


































 12%|█▏        | 1885/15750 [11:34<48:59,  4.72it/s]
 12%|█▏        | 1890/15750 [11:36<48:40,  4.75it/s]




















100%|██████████| 68/68 [00:40<00:00,  1.80it/s]


































 14%|█▍        | 2201/15750 [13:37<47:47,  4.72it/s]
 14%|█▍        | 2205/15750 [13:38<47:36,  4.74it/s]





















 99%|█████████▊| 67/68 [00:42<00:00,  1.56it/s]



































 16%|█▌        | 2520/15750 [15:43<46:15,  4.77it/s]
{'loss': 0.0967, 'learning_rate': 1.329065079517968e-05, 'epoch': 8.0}






















 96%|█████████▌| 65/68 [00:43<00:01,  1.50it/s]

































 18%|█▊        | 2833/15750 [17:49<45:31,  4.73it/s]
 18%|█▊        | 2835/15750 [17:50<45:27,  4.74it/s]




















 99%|█████████▊| 67/68 [00:40<00:00,  1.63it/s]


































 20%|█▉        | 3146/15750 [19:55<44:13,  4.75it/s]
 20%|██        | 3150/15750 [19:56<43:54,  4.78it/s]





















 99%|█████████▊| 67/68 [00:42<00:00,  1.57it/s]


































 22%|██▏       | 3460/15750 [21:59<42:39,  4.80it/s]
 22%|██▏       | 3465/15750 [22:00<42:48,  4.78it/s]




















 99%|█████████▊| 67/68 [00:40<00:00,  1.68it/s]


































 24%|██▍       | 3777/15750 [24:04<41:54,  4.76it/s]
 24%|██▍       | 3780/15750 [24:04<42:10,  4.73it/s]






















 96%|█████████▌| 65/68 [00:42<00:01,  1.51it/s]

































 26%|██▌       | 4089/15750 [26:09<40:54,  4.75it/s]
 26%|██▌       | 4095/15750 [26:11<40:51,  4.75it/s]






















 97%|█████████▋| 66/68 [00:43<00:01,  1.51it/s]



































 28%|██▊       | 4410/15750 [28:16<39:32,  4.78it/s]
{'loss': 0.0812, 'learning_rate': 1.139385120677726e-05, 'epoch': 14.0}




















100%|██████████| 68/68 [00:41<00:00,  1.81it/s]



































 30%|███       | 4725/15750 [30:18<38:32,  4.77it/s]
{'loss': 0.0765, 'learning_rate': 1.1077550587218363e-05, 'epoch': 15.0}





















 94%|█████████▍| 64/68 [00:40<00:02,  1.58it/s]

































 32%|███▏      | 5036/15750 [32:24<37:27,  4.77it/s]
 32%|███▏      | 5040/15750 [32:25<37:16,  4.79it/s]






















 97%|█████████▋| 66/68 [00:42<00:01,  1.60it/s]

































 34%|███▍      | 5349/15750 [34:34<36:05,  4.80it/s]
 34%|███▍      | 5355/15750 [34:35<36:01,  4.81it/s]






















 97%|█████████▋| 66/68 [00:43<00:01,  1.50it/s]


































 36%|███▌      | 5667/15750 [36:42<35:49,  4.69it/s]
 36%|███▌      | 5670/15750 [36:43<35:24,  4.74it/s]




















 99%|█████████▊| 67/68 [00:40<00:00,  1.69it/s]



































 38%|███▊      | 5985/15750 [38:44<34:29,  4.72it/s]
 38%|███▊      | 5985/15750 [38:45<34:29,  4.72it/s]





















 99%|█████████▊| 67/68 [00:43<00:00,  1.54it/s]



































 40%|████      | 6300/15750 [40:49<32:43,  4.81it/s]
{'loss': 0.0669, 'learning_rate': 9.496047489423862e-06, 'epoch': 20.0}





















 99%|█████████▊| 67/68 [00:43<00:00,  1.49it/s]


 40%|████      | 6300/15750 [42:15<1:03:22,  2.49it/s]
{'train_runtime': 2535.1104, 'train_samples_per_second': 99.187, 'train_steps_per_second': 6.213, 'train_loss': 0.21839029342409164, 'epoch': 20.0}